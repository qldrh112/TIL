# 20240610
## AI 드론봇 - 8


#### 8. 성능 최적화

##### 성능 최적화
딥러닝은 성능을 최적화 할 수 있는 다양한 방법이 있다.  

###### 데이터를 사용한 성능 최적화
데이터가 많을수록 성능이 좋아진다.  
- 데이터 수집(가장 좋음)
- 최대한 많은 데이터 수집하기
- 데이터 생성하기(RandomResizeCrop 등)
- 데이터 범위 조정하기

###### 알고리즘을 이용한 성능 최적화
머신 러닝과 딥러닝 알고리즘은 상당히 많다.  
그러므로 우리는 유사한 용도의 알고리즘을 공부해 사용하면서 최적의 알고리즘을 선택해야 함  

###### 알고리즘 튜닝을 위한 성능 최적화
성능 최적화를 하는 데 가장 많은 시간이 소요되는 부분  
- 진단: 성능 향상이 멈추었을 때, 모델을 평가하여 과적합 때문인지, 아니면 다른 원인으로 성능에 문제가 있는지 살펴본다.
  ex1. 훈련 성능이 검증보다 눈에 좋게 좋다면 과적합을 의심해보기 => 규제화 적용  
  ex2. 훈련 성능과 검증 모두 좋지 않다면 과소적합을 의심해보기 -> 네트워크 구조 적용, epoch 수 늘리기  
  ex3. 훈련 성능이 검증을 넘어서는 변곡점에서 조기 종료 고려하기  
- 가중치: 초깃값은 작은 난수를 사용하거나 오토인코더같은 비지도 학습을 통한 사전 학습 이후 지도 학습을 진행하는 것도 방법
- 학습률: 모델의 네트워크 구성에 따라 다르기 때문에 크거나 작은 임의의 난수를 선택하여 학습 결과를 보고 조금씩 수정하기, 네트워크의 계층이 많으면 학습률은 높게, 그렇지 않다면 학습률은 낮게 설정하는 것이 일반적이다.
- 활성화 함수: 활성화 함수의 변경은 신중하게, 손실 함수도 함께 변경해야 하는 경우도 많기 때문, 일반적으로 활성화 함수로 시그모이드나 하이퍼볼릭 탄젠트를 사용했다면 출력은 소프트맥스나 시그모이드 함수를 많이 선택함
- 배치와 애포크: 일반적으로 큰 에포크와 작은 배치를 사용하는 것이 2022년 기준 딥러닝의 트렌드, 적절한 배치 크기를 위해 훈련 데이터셋의 크기와 동일하게 하거나 하나의 배치로 훈련을 시키는 등 다양한 방법을 사용해보는 것이 좋다.
- 옵티마이저 및 손실 함수: 옵티마이저는 보통 경사 하강법을 많이 사용, 네트워크 구성에 따라 차이가 있지만, 아담이나 RMSProp 등도 좋은 성능을 보임, 다양하게 적용해보고 성능이 좋은 것을 사용하라.
- 네트워크 구성(네트워크 토폴로지): 최적의 네트워크의 구성도 쉽게 알 수 없어 네트워크 구성을 변경해가며 성능을 테스트해야 함
  ex1. 하나의 은닉층에 여러 개 포함(네트워크를 넓힘)
  ex2. 네트워크를 들리되 뉴런 개수를 줄임(네트워크를 깊게 팜)
  ex3. 두 가지를 결합

###### 앙상블을 이용한 성능 최적화
앙상블: 두 개 이상의 모델을 섞어서 사용하는 것  

> 알고리즘 튜닝을 위한 성능 최적화는 하이퍼파라미터에 대한 경우의 수도 모두 고려해야 하기 때문에 훈련 모델이 수십 번에서 수백 번 필요할 수 있다, 성능향상은 단기간에 해결되는 것이 아니고 수많은 시행착오를 겪어야 함

##### 하드웨어를 이용한 성능 최적화
딥러닝에서 GPU를 이용하면 시간 단축이 가능하다.  

###### CPU와 GPU 사용의 차이
CPU 5개보다 GPU 1개가 더 성능이 좋다.  

CPU: 연산을 담당하는 ALU와 명령어를 해석하고 실행하는 컨트롤, 데이터를 담아두는 캐시로 이루어짐  
= 명령어 입력에 따른 직렬 처리 방식  
> 한 번에 하나의 명령어만 처리하기에 ALU의 개수가 많을 이유가 없다.

GPU: 병렬 처리를 위해 개발, 캐시 메모리의 비중은 낮고, ALU의 개수가 많아짐 => 서로 다른 명령어를 동시에 병렬적으로 처리하도록 설계  
> 많은 ALU로 이루어져 있기 때문에 병렬 처리에 특화, 하나의 코어에 ALU 수백 ~ 수천 개 장착 => 3D 그래픽 작업 등을 빠르게 수행 가능  

CPU와 GPU의 용도는 다를 수 밖에 없다.  

- 파이썬이나 매트랩처럼 행렬 연산을 많이 사용하는 재귀 연산은 대표적인 직렬 연산, 3 x 3 행렬에서 A열이 처리되고, B열, C열이 처리되는 순차적 연산은 CPU가 적합
- 역전파처럼 복잡한 미적분은 대표적인 병렬 연산, A열, B열, C열을 얼마나 동시에 처리하느냐에 따라서 계산 시간이 달라짐.

###### GPU를 이용한 성능 최적화
Windows 환경에서 GPU용 파이토치를 설치하기 위해서 'CUDA', cuDNN이 필요  

CUDA(Computed Unified Device Architecture): NVIDA에서 개발한 GPU 개발 툴, 많은 양의 연산을 동시에 처리할 수 있게 해줌, 딥러닝, 채굴같은 수학적 계산에 많이 사용   

[CUDA 설치 과정]  
1. 장치 관리자 -> 디스플레이 어댑터 -> 그래픽 카드 장착 여부 확인
참고: https://www.nvidia.com/en-us/geforce/10-series/ 그래픽 카드 성능 확인  
2. CUDA 툴킷 설치
  2.1. https://en.wikipedia.org/wiki/CUDA 에서 자신의 GPU 모델을 지원하는 CUDA 툴킷 버전을 확인, 파이토치에서는 CUDA 11.8과 CUDA 12.1을 지원한다.
  2.2. https://developer.nvidia.com/cuda-toolkit-archive/ 에서 적절한 툴킷 버전을 선택하여 다운로드 한다.  
  2.3. 자신의 컴퓨터에 맞게 선택하고 내려 받는다.  
  2.4 설치 파일을 실행에 빠른 설치를 한다.  
  2.5. 시스템 변수에 CUDA 항목이 등록되었는지 확인한다.
    2.5.1. 만약 등록이 안 되어 있다면, 검색해서 찾아본다.  
3. cuDNN 설치
  3.1. https://developer.nvidia.com/rdp/cudnn-download/ 에 접속한다. 
  3.2. 멤버십에 가입한다.
  3.3. 자신에게 맞는 cuda 버전을 선택하고 설치한다.
  3.4. 압축을 해제한다.
  3.5. bin, include, lib 폴더를 복사하고, 설치한 CUDA의 경로(일반적으로 C:\ProgramFiles\NVIDIA GPU Computing Toolkit\CUDA\자신의 버전에 있음)에 알맞게 덮어씁니다.
4. GPU 설치 확인 `명령 프롬프트` -> `Nvcc --version`  
5. 파이토치 GPU 버전 설치
  5.1. https://pytorch.org/get-started/locally/ 에서 자신에게 맞는 옵션을 찾아서 아래 나오는 run this command에 있는 내용을 복사하여 가상 환경에서 설치를 한다.

##### 하이퍼파라미터를 이용한 성능 최적화
* 정규화: 데이터 범위를 사용자가 원하는 범위로 제한하는 것, 특성 범위를 조정한다는 의미로 특성 스케일링이라고도 함  
ex. 이미지 데이터는 픽셀 정보로 0~255 사이의 값을 갖는데 이를 255로 나누면 0~1 사이의 값을 가짐  
* 규제화: 모델 복잡도를 줄이기 위해 데이터가 네트워크에 들어가기 전에 필터를 적용하는 것
규제를 이용하여 모델 복잡도를 줄이는 방법(드롭 아웃, 조기 종료,)
* 표준화: 기존 데이터를 평균은 0, 표준편차는 1인 형태의 데이터로 만드는 방법, 표준화 스칼라나 z-스코어 정규화라고도 함
평균을 기준으로 얼마나 떨어져 있는지 살펴볼 때 사용, 데이터 분포가 가우시안 분포를 따를 때 유용함  

###### 배치 정규화를 이용한 성능 최적화
- 배치 정규화: 기울기 소멸이나 기울기 폭발 같은 문제를 해결하기 위한 방법, 기울기 소멸이나 폭발 문제를 해결하기 위해 손실 함수로 렐루를 사용하거나 초깃값 튜닝, 학습률 등을 조정함  

기울기 소멸과 폭발의 원인은 내부 공변량 변화로 인함. 네트워크 의 각 층마다 활성화 함수가 적용됨녀서 입력 값의 분포가 계속 바뀌는 현상  
따라서 분산된 분포를 정규분포로 만들기 위해 표준화와 유사한 방식을 미니 배치에 적용하여 평균은 0으로, 표준 편차는 1로 유지하도록 함  
[과정]  
1. 미니배치(표본을 뽑아 무작위로 샘플링하는 것) 평균을 구함
2. 미니 배치의 분산과 표준 편차를 구함
3. 정규화를 수행
4. 스케일을 조정(데이터 분포 조정)

매 단계마다 활성화 함수를 거치며 데이터셋 분포가 일정해지기에 속도를 향상시키며 다음과 같은 단점 존재  
1. 배치 크기가 작을 때는 정규화 값이 기존 값과 다른 방향으로 훈련됨
ex. 분산이 0일 때  
2. RNN은 네트워크 계층별로 미니 정규화를 적용해야 하기 때문에 모델이 더 복잡해짐

###### 드롭아웃을 이용한 성능 최적화
과적합: 훈련 데이터셋을 과하게 학습하는 것  
훈련 데이터셋은 실제 데이터셋의 부분 집합이므로 훈련 데이터셋에 대해서는 오류가 감소하지만, 테스트 데이터셋에 대해서는 오류가 증가  
> 훈련 데이터셋에 대해 훈련을 계속하면 오류는 줄어들지만, 테스트 데이터셋에 대한 오류는 어느 순간부터 증가  

드롭아웃: 훈련할 때, 일정 비율의 뉴런만 사용하고, 나머지 뉴런에 해당하는 가중치는 업데이트하지 않는 방법  
매 단계마다 사용하지 않는 뉴런을 바꾸어가며 훈련시킴  
> 노드를 임의로 끔면서 학습하는 방법, 은닉층에 배치된 노드 중 일부를 임의로 끄면서 학습.  
테스트 데이터로 평가할 때는 노드를 모두 사용하여 출력하되 노드 삭제 비율을 곱해서 성능을 평가  
드롭 아웃을 사용하면 훈련 시간이 길어지나 모델 성능을 향상시킬 수 있음  

`images.shape`: torch.Size([4, 1, 28, 28]), 1은 채널을 나타냄, 1이면 흑백, 3이면 컬러  
파이토치의 이미지 데이터셋: [배치 크기, 채널, 너비, 높이]  
맷플롯립의 이미지 데이터셋: [너비, 높이, 채널]  

Linear 층을 거치면서 결과 분석 결과 클래스 개수에 가까워짐  
선형 계층의 입력은 너비와 높이를 1차원으로 늘린 것  
ex. 28 x 28 크기의 선형 계층 입력은 784  
output = Wx + b  
선형 계층을 거치며 가중치 행렬에 따라서 출력차원의 크기로 반환하는 것
ReLU 활성화 함수는 비선형성을 추가하는 활성화 함수  
복잡한 데이터를 표현하거나 다층 신경망의 효과를 얻기 위해 비선형성을 추가한다.  

`x.view(x.size(0), -1)`: 입력 데이터는 (batch_size, 28, 28) 형태의 입력을 (batch_size, 784)로 바꿈  
이후 classifier 함수에 적용  

배치 정규화를 사용하는 이유는 은닉층에서 학습을 진행할 때마다 입력 분포가 변하면서 가중치가 엉뚱한 방향으로 갱신되는 문제가 종종 발생하기 때문  
> 신경망의 깊이가 깊어질수록 학습할 때 가정했던 입력 분포가 변화되어 엉뚱한 학습을 진행할 수 있는데 배치 정규화를 통해 입력 분포를 고르게 맞추어 줄 수 있다.  

배치 정규화는 완전연결층과 합성곱층 뒤, 활성화 함수 앞에 위치  

배치 정규화를 하지 않더라도 배치 정규화를 한 것보다 성능이 더 좋을 수도 있다.  

`enumerate(iter, 카운터의 시작 값)`: 몇 번째부터 반복을 돌릴 지 결정  

`torch.unsqueeze(torch.linspace(-1, 1, N), 1)`: 훈련 데이터셋이 -1 ~ 1의 값을 갖도록 조정하는 코드  
`torch.linspace(-1, 1, 50)`: -1에서 1 사이의 범위에서 N개의 균등한 값을 갖는 텐서를 생성하겠음

``` python
import torch
# 0 ~ 10을 100으로 분할
print(torch.linspace(0, 10, 100))
print('-' * 80)
print(torch.linspace(0, 10, 5))

"""
tensor([ 0.0000,  0.1010,  0.2020,  0.3030,  0.4040,  0.5051,  0.6061,  0.7071,
         0.8081,  0.9091,  1.0101,  1.1111,  1.2121,  1.3131,  1.4141,  1.5152,
         1.6162,  1.7172,  1.8182,  1.9192,  2.0202,  2.1212,  2.2222,  2.3232,
         2.4242,  2.5253,  2.6263,  2.7273,  2.8283,  2.9293,  3.0303,  3.1313,
         3.2323,  3.3333,  3.4343,  3.5354,  3.6364,  3.7374,  3.8384,  3.9394,
         4.0404,  4.1414,  4.2424,  4.3434,  4.4444,  4.5455,  4.6465,  4.7475,
         4.8485,  4.9495,  5.0505,  5.1515,  5.2525,  5.3535,  5.4545,  5.5556,
         5.6566,  5.7576,  5.8586,  5.9596,  6.0606,  6.1616,  6.2626,  6.3636,
         6.4646,  6.5657,  6.6667,  6.7677,  6.8687,  6.9697,  7.0707,  7.1717,
         7.2727,  7.3737,  7.4747,  7.5758,  7.6768,  7.7778,  7.8788,  7.9798,
         8.0808,  8.1818,  8.2828,  8.3838,  8.4848,  8.5859,  8.6869,  8.7879,
         8.8889,  8.9899,  9.0909,  9.1919,  9.2929,  9.3939,  9.4949,  9.5960,
         9.6970,  9.7980,  9.8990, 10.0000])
--------------------------------------------------------------------------------
tensor([ 0.0000,  2.5000,  5.0000,  7.5000, 10.0000])
"""
```

`torch.unsqueeze`: unsqueeze()는 차원을 늘리기 위해 사용  
`torch.unsqueeze(torch.linspace(-1, 1, N), 1)`: `torch.linspace(-1, 1, N)`의 결과 텐서의 첫 번재 자리에 차원을 증가하겠다는 것  

``` python
import torch
# 0 ~ 10을 100으로 분할
print(torch.linspace(0, 10, 5))
print('-' * 80)
print(torch.unsqueeze(torch.linspace(-1, 1, 5), 1))
"""
tensor([ 0.0000,  2.5000,  5.0000,  7.5000, 10.0000])
--------------------------------------------------------------------------------
tensor([[-1.0000],
        [-0.5000],
        [ 0.0000],
        [ 0.5000],
        [ 1.0000]])
"""
```

`x_train + noise * torch.normal(torch.zeros(N, 1), torch.ones(N, 1))`: 훈련 데이터셋 값의 범위가 정규분포를 갖도록 조정함  
`torch.normal(평균, 표준 편차)`: 정규분포로부터 무작위 표본 추출을 위해 사용  
`torch.zeros(N, 1)`: 0값을 갖는 N x 1 텐서를 생성  
`torch.ones(N, 1)`: 1값을 갖는 N x 1 텐서를 생성  

``` python
import torch
print(torch.normal(torch.zeros(5, 1), torch.ones(5, 1)))
"""
tensor([[-0.8765],
        [-0.5125],
        [ 0.2596],
        [-2.6531],
        [ 0.8823]])
"""
```

`plt.scatter(x축 데이터, y축 데이터, c=마커, alpha=마커의 불투명도(0~1), label='범례의 데이터')`: 데이터를 그래프상에 점으로 출력해서 데이터 분포를 확인하고자 할 때 사용  

`plt.pause(0.5)`는 애니메이션이나 실시간 그래픝 업데이트를 위해 사용, 일정 시간 동안 그래프를 일시정지하고, 이 시간을 이용해 화면을 업데이트하거나 사용자와 상호 작용을 처리할 수 있음  

드롭아웃을 적용하지 않으면 훈련 데이터를 쫓아가는 모습을 발견할 수 있다.  
이것이 심화되면 과적합이라고 한다.  


###### 조기 종료를 이용한 성능 최적화
조기 종료는 뉴럴 네트워크가 과적합을 회피하는 규제 기법, 훈련 데이터와 별도로 검증 데이터를 준비하고, 매 에포크마다 검증 데이터에 대한 오차를 측정하여 모델의 종료 시점을 제어  
> 과적합 발생 전까지 학습에 대한 오차와 검증에 대한 오차 모두 감소하지만, 과적합이 발생하면 훈련 데이터셋에 대한 오차는 감소하는 반면 검증 데이터셋에 대한 오차는 증가함 -> 검증 데이터셋에 대한 오차가 증가하는 시점에서 학습을 멈추도록 조정  

RAM의 성능에 따라서 batch_size를 조정할 수 있다.  16 ~ 24 GB 정돈느 한 번에 32개 정도  

학습률 감소: 학습이 진행되는 과정에서 학습률을 조금씩 낮추어 주는 성능 튜닝 기법 중 하나, 학습률 스케줄러를 통해 주어진 'patience' 횟수만큼 검증 데이터셋에 대한 오차가 감소가 없으면 주어진 'factor'만큼 학습률을 감소시켜 모델 학습의 최적화가 가능하게 도와 줌  

`self.lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='min', patience=self.patience, min_lr=min_lr, verbose=True)`: 학습 과정에서 모델 성능에 대한 개선이 없을 때 학습률 값을 조절하여 모델의 개선을 유도하는 콜백 함수  
  - `r_scheduler.ReduceLROnPlateau`: `ReduceLROnPlateau`는 검증 데이터셋에 대한 오차의 변동이 없으면 학습률을 factor배로 감소시킴
  - `optimizer`: 파라미터(가중치)를 갱신시키는 부분으로, 여기에서는 optim.Adam을 사용
  - `mode`: 언제 학습률을 조정할 지에 대한 기준이 되는 값, min이면 모델의 오차가 내려가지 않을 때, max이면 모델의 정확도가 올라가지 않을 때
  - `patience`: 학습률을 업데이트하기 전에 몇 번의 에포크를 기다려야 하는지 결정하는 것
  - `factor`: 학습률을 얼마나 감소할 지 결정하는 파라미터, 새로운 학습률은 `기존 학습률 x factor`
  - `min_lr`: 학습률의 하한선
  - `verbose`: 초기 종료의 시작과 끝을 출력하기 위해 사용, 1은 조기 종료가 안내 메시지, 0은 그런 거 없음

콜백 함수: 명시적으로 함수 호출을 하는 것이 아니라 함수 등록만 하고, 특정 이벤트 발생에 의해 함수를 호출하고 처리하도록 하는 것이 콜백 함수  
이거 js의 그것과 맥락이 비슷한 거 같은데?  

keras에서는 콜백을 이용하여 손쉽게 조기 종료를 구현할 수 있다.  

``` python
from keras.callbacks import ModelCheckpoint, EarlyStopping

# 파일명 지정
checkpoint = ModelCheckpoint('checkpoint-epoch.h5'.format(EPOCH, BATCH_SIZE),
                             # val_loss 값이 개선되었을 때 호출
                             monitor='val_loss',
                             # 로그 출력
                             verbose=1,
                             # 가장 최적의 값만 저장
                             save_best_only=True,
                             # auto의 의미는 시스템이 알아서 best 값을 찾으라는 것
                             mode='auto',
                             )

earlystopping = EarlyStopping(monitor='val_loss',   # 학습률 업데이트 기준 설정
                              patience=10,  # 에포크가 진행되는 동안 10번 동안 오차가 개선되지 않으면 종료
                              )
```

함수에 넘겨주는 인수 값에 따라서 학습률 감소나 조기 종료를 하도록 해야 하는데 이때, `argparse` 라이브러리를 활용할 수 있다.  
`ArgumentParser()`를 이용하여 변수와 타입을 정의하고, `add_argument()`를 이용해 변수에 인수값을 하나씩 추가함 그리고 `parse_args()를 통해 사용자로부터 입력받은 args 변수를 지정

`parser.add_argument()`: 원하는 인수 값을 추가하는 코드  
parser.add_argument()는 인수 개수만큼 만들어 줌  
- 첫 번째 파라미터: 옵션 문자열의 이름으로 명령을 실행할 때 사용  
ex. `> python main.py --lr-scheduler`  
- dest: 입력 값이 저장되는 변수
- action: 'store_true'이면 입력 값을 dest 파라미터에 의해 생성된 변수에 저장  

`img should be Tensor Image. Got <class 'PIL.Image.Image'>`: 이미지가 텐서로 변환되지 않았다.  

pytorch에서 `verbose`의 의미: 함수 실행 시 발생하는 상세한 정보릂 표준 출력으로 보여줄 지 여부를 나타내는 옵션  
0: 출력하지 않음, 1: 자세한 정보를 출력, 2: 간략한 정보만 출력  

1. 훈련 및 검증 데이터에서 전처리 이유: 물리적인 데이터 증가는 없지만, 데이터의 형태 변화로 인해 다양성과 일반화 성능 증가

2. `requires_grad=True`: 해당 텐서의 기울기를 계산하고, 역전파 과정에서 이 기울기를 통해 파라미터가 업데이트할 수 있도록 설정, 모델 훈련 시에는 True로 설정

3. resnet50에서 이미 훈련한 모델을 가지고 사용할 때는 requires_grad가 True일 필요가 없을 것이다.

4. `p.numel()`: 텐서 p에서 모든 원소의 수 반환, 파라미터 텐서의 총 원소 개수

5. tqdm에서 total의 의미: 진행 막대의 총 반복 횟수, 한 에포크 동안 진행되는 배추의 총 횟수

6. total_loss는 왜 counter로 나누고, total_accuracy는 total로 나눌까? running_loss는 배치의 손실을 누적한 값이므로 배치의 총 개수로 나누어야 함, running_correct는 모든 배치에서 맞춘 총 예측의 개수, 그러므로 전체 정확도를 계산하기 위해 전체 데이터의 개수로 나눠야 함

7. 명령줄 인수: 스크립트를 실행할 때 추가로 전달할 수 있는 옵션이나 값을 의미
ex.`python main.py --lr-scheduler` 를 입력 하면 `--lr-scheduler` 인수가 전달됨  

실제로 아나콘다 프롬프트에서 python early_stopping.py --early-stopping을 실행하면 만든 조기 종료 함수와 학습률 감소 함수를 모델 학습에 적용할 수 있다.  

조기 종료는 항상 성능에 좋은 영향을 끼치는 것은 아니다.  
조기 종료로 인해 모델이 제대로 학습하지 못할 수 있다.  
그렇다고 계속 훈련한다고 좋은 성능을 가져오지 못 한다.  
그러므로 데이터를 다루는 파일럿이 데이터의 특성과 내용을 잘 이해하고 적절한 방법을 적용하는 것이 중요하다.  
모델의 성능은 정확도뿐만 아니라 오차도 존재한다.  

학습률 스케쥴러를 이용한 학습률 조정 기법과 조기 종료가 모델 성능을 향상시키는 데 도움을 줄 수 있다.  
특히 조기 종료는 성능보다 자원(CPU/메모리)의 효율성을 향상시키는 것을 꾀할 수 있다.  
그리고 반드시 이것을 적용하는 것이 아니라 기존의 그래프를 해석하고, 판단하여 의사 결정하는 것이 중요하다.  